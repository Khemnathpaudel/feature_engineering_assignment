{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3LCwWVXWYZUJ"
      },
      "outputs": [],
      "source": [
        "#1. What is a parameter?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ans: Parameter: a parameter is a variable within the model that is learned from the training data.\n",
        "#These parameters are adjusted during the training process to minimize errors and improve the model's performance.\n",
        "#Examples include the weights in nural network,coefficients in a linear regression model."
      ],
      "metadata": {
        "id": "S_merz_YaV20"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. What is correlation? What does negative correlation mean?"
      ],
      "metadata": {
        "id": "oXbQkQm-aqC5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ans: correlation: it is a measure of how two variables are related with one other.\n",
        "#negative correlation: it means that as one variable increases the other decreases"
      ],
      "metadata": {
        "id": "rwLc6exxbxuD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Define Machine Learning. What are the main components in Machine Learning?"
      ],
      "metadata": {
        "id": "M1wx8_Itbxw3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: the subfield of computer science that gives the computer the ability to learn pattern in the data without explicitly programmed.\n",
        "# The main components of machine learning are:\n",
        "# 1.Data: the raw information used to train the model.\n",
        "# 2 Algorithms: the methods used to analyze data and learn patterns.\n",
        "# 3 Model: The result of training the algorithm on the data, which makes predictions or decisions.\n",
        "# 4 Training: The process of teaching the algorithm on the data,which makes predictions or decisions.\n",
        "# 5 Evaluation:Assessing the model's preformance and accuracy"
      ],
      "metadata": {
        "id": "IKqH_4t1bxzy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.How does loss value help in determining whether the model is good or not?"
      ],
      "metadata": {
        "id": "ze78oL4_eerP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: the loss value measures how well or poorly a machine learning model is performing,\n",
        "# lower loss value means the model's predictions are closer to the actual outcomes,indicating better performance,\n",
        "# conversly, a higher value suggests that the model's predictions are off, which means it needs improvement."
      ],
      "metadata": {
        "id": "L_SzFNTQeetG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. What are continuous and categorical variables?"
      ],
      "metadata": {
        "id": "zJiyEIZheexV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#continuous variables:continuous variables are numerical values that can take on any value within a range.\n",
        "# For example: height of person, they can be measured to any level of precision.\n",
        "\n",
        "#categorical variables: it represent distinct categories or groups. For example, eye color(blue,brown,green) and\n",
        "# type of fruit(apple,orange,banana)\n"
      ],
      "metadata": {
        "id": "fdD-4B_8ee0Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.How do we handle categorical variables in Machine Learning? What are the common techniques?"
      ],
      "metadata": {
        "id": "V_231mtSkHOm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: handling categorical varaibles in machine learning involves converting them into a numerical format that models can understand.\n",
        "# common techinques include:\n",
        "# 1. one-hot encoding: converts each category into a binary columns(0 or 1).for example,'red','blue','green'\n",
        "# becomes three columns:[1,0,0],[0,1,0],[0,0,1]\n",
        "# 2.Label Encoding:Assings each category a unique integer.For example, 'red'=1,'blue'=2,'green'=3.\n",
        "# 3.Binary encoding: Combines the properties of both one-hot and label encoding. For example,'red'=1,'blue'=2,'green'=3,and then these numbers\n",
        "#  are converted to binary."
      ],
      "metadata": {
        "id": "lGV-MG2GkHSI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. What do you mean by training and testing a dataset?"
      ],
      "metadata": {
        "id": "LKY7vXuRkHVz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ans: In machine learning, training a dataset means using data to teach the modelto make predictions or decisions,\n",
        "# the model learns patterns from the data.\n",
        "# testing a dataset means evaluating the model's performance by using a separate set of data that the model hasn't seen before, this helps to\n",
        "# check how well the model can generalize to new, unseen data.\n"
      ],
      "metadata": {
        "id": "eFFwXpnPm7mu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. What is sklearn.preprocessing?"
      ],
      "metadata": {
        "id": "3TFeXuanm7oz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans:sklearn.preprocessing is a module in the scikit-learn library,which is used to prepare data for machine learning models.\n",
        "# it includes various tools to scale, transform, and normalize data, making it easier for algorithms to process and learn from it.\n",
        "#example include standardscaler for standardizing features and labelencoder for converting categorical labels into numerical values"
      ],
      "metadata": {
        "id": "bSp7twCGp0Gw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. What is a Test set?"
      ],
      "metadata": {
        "id": "FzIRe6P9p0Ib"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ans: a test set is a portion of data used to evaluate the performance of a machine learning model after it has been trained.\n",
        "#It helps determine how well the model can make predictions on new,unseen data."
      ],
      "metadata": {
        "id": "R1rKT2qGp0M1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?"
      ],
      "metadata": {
        "id": "tntKEhhgr3JR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: split data: use train_test_split from sklearn.model_selection to divide data into training and testing sets.\n",
        "# approach ml problem:\n",
        "# -understand the problem\n",
        "# -collect and prepate data\n",
        "# -explore data\n",
        "# -select and train a model\n",
        "# -evaluate and tune the model\n",
        "# -deploy and monitor the model"
      ],
      "metadata": {
        "id": "MPBSzMngr2y7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Why do we have to perform EDA before fitting a model to the data?"
      ],
      "metadata": {
        "id": "ett-YXO8r2wL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans:Performing exploratory data analysis(EDA) is curcial before fitting a model because it helps you understand\n",
        "# the data's structure, detect patterns,identify outliers, and handle missing values.\n",
        "# this ensures you have clean, relevant data and can make informed decisions about how to model it effectively"
      ],
      "metadata": {
        "id": "lx_9Duh2m7sq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. What is correlation?"
      ],
      "metadata": {
        "id": "DuSfhyzUaqGe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: correlation is a measure of how two variables move together. when two variables have a high correlation,\n",
        "# it means that changes in one variable are often matched by changes in the other, either in the same direction(positive correlation)\n",
        "# or opposite directions(negative correlation)"
      ],
      "metadata": {
        "id": "9aRh595LwuGW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.What does negative correlation mean?\n"
      ],
      "metadata": {
        "id": "zY_7T9AKuqfr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: a negative correlation means that as one variable increases , the other decreases.For example. as the price of a product increases,\n",
        "# the demand for it might decrease"
      ],
      "metadata": {
        "id": "qzjbwCBUyK-0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14. How can you find correlation between variables in Python?"
      ],
      "metadata": {
        "id": "7AFEcyPUyLBt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#create a sample DataFrame\n",
        "data={'var1':[1,2,3,4,5],'var2':[10,20,30,40,50]}\n",
        "data=pd.DataFrame(data)\n",
        "#calculate the correlation matrix\n",
        "corr_matrix=data.corr()\n",
        "print('the correaltion between var1 and var2 is:',corr_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzDsuJtuqj3",
        "outputId": "b30fa772-f887-463b-a79b-7bd0cc44007c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the correaltion between var1 and var2 is:       var1  var2\n",
            "var1   1.0   1.0\n",
            "var2   1.0   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15. What is causation? Explain difference between correlation and causation with an example"
      ],
      "metadata": {
        "id": "_mGwMe5I1216"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ans: causation: it means that one event directly causes another event to happen.\n",
        "# correlation is when two variables are related but one does not necessarily cause the other.\n",
        "#example:ice cream sales and sunburns often increase at the same time(correaltion),but buying ice cream doesn't cause sunburns. The actual\n",
        "#cause(causation) is hot weather,which leads to both increased ice cream sales and more sunburns."
      ],
      "metadata": {
        "id": "zQ5ZwgPZ12zL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. What is an Optimizer? What are different types of optimizers? Explain each with an example"
      ],
      "metadata": {
        "id": "cOjhVdTO8kw9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #ans: an optimizer in machine learning is an algorithm that adjusts the parameters of the model to minimize the loss function and imporve accuracy.\n",
        "# Different types of optimizers include:\n",
        "# 1.Gradient Descent:Updates parameters by moving them in the direction of the steepest descent fo the loss function.\n",
        "# -example:Batch Gradient Descent,which updates parameters using the entire dataset.\n",
        "# 2. Stochastic Gradient Descent(SGD): similar to Gradient Descent but updates parameters using one data point at a time.\n",
        "# -example:online learning,where the model updates continuously with each new data point.\n",
        "# 3. Mini-Batch Gradient Descent: Combines the aprroaches of Batch and SGD by updating parameters using small batches of data.\n",
        "#  example: Training a neural network with mini-batches to balance efficiency and convergence.\n",
        "# 4 Adam (Adaptive Moment Estimation):Combines the benefits of SGD with adaprive learning rates for each parameter.\n",
        "#  example:Training deep learning models like CNNs, where Adam adjusts learning rates based on gradients.\n",
        "# These optimizers help in efficiently training machine learning models by tweaking their parameters to minimize errors.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pg3vdnhZ0WcK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. What is sklearn.linear_model ?"
      ],
      "metadata": {
        "id": "VPX2rLcG3fbN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: sklearn.linear_model is a module in the scikit-learn library in python that provides various linear mdoels for regression and classification\n",
        "# tasks. These models include linear regression,logistic regression ,ridge,lasso and more.\n",
        "# They are used to make predictive or classify data based on a linear relationship between the input features and the target variable."
      ],
      "metadata": {
        "id": "qzwVCfSM0WgJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18. What does model.fit() do? What arguments must be given?"
      ],
      "metadata": {
        "id": "VzRcO3wQ8ndc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model.fit() function trains a machine learning model using the given data.\n",
        "# It adjusts the model's parameters to minimize errors and improve accuracy.\n",
        "# Arguments needed:\n",
        "# X:feature data(input variables)\n",
        "# y:target data(output variable)\n",
        "# example:\n",
        "# model.fit(X,y)\n",
        "# this command fits the model to the provided data"
      ],
      "metadata": {
        "id": "e4h_66v5h5je"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. What does model.predict() do? What arguments must be given?"
      ],
      "metadata": {
        "id": "WPfkA-TZh5lh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model.predict() function uses a trained model to make predictions on new unseen data.\n",
        "# Arguments needed:\n",
        "# X_new: new feature data(input variables) for which you want predictions.\n",
        "# example:\n",
        "# model.predict(X_new)\n",
        "# this command provides predictions based on the input data given."
      ],
      "metadata": {
        "id": "bp3Uu50mh5o3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. What are continuous and categorical variables?\n"
      ],
      "metadata": {
        "id": "cT07mPeZh5r3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: continuous variables:continuous variables are numerical values that can take on any value within a range.\n",
        "# For example: height of person, they can be measured to any level of precision.\n",
        "\n",
        "#categorical variables: it represent distinct categories or groups. For example, eye color(blue,brown,green) and\n",
        "# type of fruit(apple,orange,banana)\n"
      ],
      "metadata": {
        "id": "gtdMNv59jhck"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21. What is feature scaling? How does it help in Machine Learning?"
      ],
      "metadata": {
        "id": "ueAEaum6jhff"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans:Feature scaling is the process of adjusting the values of features to a common scale,usually between 0 and 1, or -1 and 1.\n",
        "# It helps in machine learning by ensuring that all features contribute equally to the model, preventing any single feature from\n",
        "# dominating due to its larger numerical value. This leads to faster convergence and improved performance of many algorithms."
      ],
      "metadata": {
        "id": "ouVcMAyMkP4a"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22. How do we perform scaling in Python?"
      ],
      "metadata": {
        "id": "6zwiChPikP69"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: To perform scaling in python, you can use the standardscaler from sklearn.preprocessing module.\n",
        "# example:\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler=StandardScaler()# creating an object\n",
        "# X_scaled=scaler.fit_transform(X)\n",
        "# This code standardizes the feature data X by removing the mean and scaling to unit variance,ensuring all features contribute\n",
        "# equally to the model."
      ],
      "metadata": {
        "id": "mt0CrvfQnoM2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23. What is sklearn.preprocessing?\n"
      ],
      "metadata": {
        "id": "0KHDpwWCnoQS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans:sklearn.preprocessing is a module in the scikit-learn library,which is used to prepare data for machine learning models.\n",
        "# it includes various tools to scale, transform, and normalize data, making it easier for algorithms to process and learn from it.\n",
        "#example include standardscaler for standardizing features and labelencoder for converting categorical labels into numerical values"
      ],
      "metadata": {
        "id": "RGKt-dsgnoUf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24 .How do we split data for model fitting (training and testing) in Python?"
      ],
      "metadata": {
        "id": "dgeAX6tBnoYk"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: to split data from model fitting in python, use the train_test_split function from sklearn.model_selection. Here's an example:\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X :input feature y:target variable\n",
        "# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "# this code divides the data into 80% traning and 20% testing data"
      ],
      "metadata": {
        "id": "kb_txyUzkP-U"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Explain data encoding?"
      ],
      "metadata": {
        "id": "W6bl-v8hpOEP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans: Data encoding is the process of converting categorical data (non-numeric) into a numerical format that machine learning models\n",
        "# can understand. Common techniques include:\n",
        "# 1.Label Encoding: Assigns a unique integer to each category.\n",
        "# 2.one-hot encoding: Converts each category into separate binary columns(0 or 1).\n",
        "# for example,if you have a feature 'color' with categories 'red','blue' and 'green':\n",
        "# -label encoding convert them into 0,1, and 2.\n",
        "# -one-hot encoding create three columns:[1,0,0],[0,1,0],[0,0,1]."
      ],
      "metadata": {
        "id": "wAwS8mxUpOLx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8vLhW9TpOTQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ki9id-FRpOYx"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}